{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb94d0e-5bb3-4e7e-b698-5d0cb4d3a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"/home/mohit/strategy_generation/rl_strategy\")\n",
    "os.system(\"pip install pyrcca\")\n",
    "\n",
    "import rcca\n",
    "import random\n",
    "random.seed(2)\n",
    "\n",
    "to_csv_path = \"/home/mohit/cca_output_pharma/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6af956-7518-40b0-93fe-de8a1b73b851",
   "metadata": {},
   "source": [
    "## LOADING THE INDICATOR DATA (STRATEGY GENERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467bdf1f-8c82-4656-a57b-f0106dfe1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('indicator_files/pharma_data/tdata_dtypes.pkl', 'rb') as f:\n",
    "    dts = pickle.load(f)\n",
    "\n",
    "chunksize = 30000\n",
    "tfr = pd.read_csv('indicator_files/pharma_data/total_data.csv', chunksize=chunksize, iterator=True, dtype=dts, compression=\"gzip\") #, dtype=dts\n",
    "total_data = pd.concat(tfr, ignore_index=True)\n",
    "\n",
    "keep_cols = [x for x in total_data.columns if (x[-1].isdigit())] + [\"DateTime\"]\n",
    "\n",
    "total_data = total_data[keep_cols]\n",
    "total_data = total_data.set_index(\"DateTime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb4e31-933e-4506-aebc-efd83b0013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set([x.split(\"_\")[0] for x in total_data.columns if x != \"date\"])), print(set([x.split(\"_\")[1] for x in total_data.columns if x != \"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d8127-a3d3-4427-abdc-f0cddbb86818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939b558-3d6c-44b1-adb0-dd7153f6259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_train_start = dt.date(2016, 1, 1)\n",
    "non_train_end = dt.date(2021, 1, 1)\n",
    "\n",
    "\n",
    "total_data[\"date\"] = total_data.index.map(lambda x: x.split(\" \")[0])\n",
    "total_data[\"date\"] = pd.to_datetime(total_data[\"date\"], format=\"%Y-%m-%d\")\n",
    "total_data = total_data[(total_data[\"date\"].dt.date > non_train_start) & (total_data[\"date\"].dt.date < non_train_end)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98337b4b-a485-48b1-94e9-a033652f6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ls = total_data[\"date\"].dt.date.tolist()\n",
    "date_ls = sorted(list(set(date_ls)))\n",
    "# random.shuffle(date_ls)\n",
    "\n",
    "split_ = 0.8\n",
    "train_dates = date_ls[:int(len(date_ls)*split_)]\n",
    "valid_dates = date_ls[int(len(date_ls)*split_):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705f798-bbe6-4ee6-87e7-3d9170256c59",
   "metadata": {},
   "source": [
    "# BEGINNING CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1555ee-d2cd-47de-895e-f10a39c044ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## INDIVIDUAL ASSET AND INDICATOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6675b3-fb61-4a41-8db7-6a244b7ba63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [x for x in total_data.columns if (traded_asset not in x) and (indicator in x) and (x.split(\"_\")[0] not in remove_cols)] + [\"date\"]\n",
    "# Y_cols = [x for x in total_data.columns if (traded_asset in x) and (indicator in x)] + [\"date\"]\n",
    "Y_cols = [x for x in total_data.columns if (traded_asset in x) and (indicator in x) and (int(x.split(\"_\")[2]) < 3)] + [\"date\"]\n",
    "\n",
    "Y_data = total_data[Y_cols]\n",
    "X_data = total_data[X_cols]\n",
    "\n",
    "print(len(Y_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114de40-836a-416b-bc2b-63f1c706667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data_train = Y_data[Y_data[\"date\"].isin(train_dates)].drop([\"date\"], axis=1)\n",
    "Y_data_test = Y_data[Y_data[\"date\"].isin(valid_dates)].drop([\"date\"], axis=1)\n",
    "\n",
    "X_data_train = X_data[X_data[\"date\"].isin(train_dates)].drop([\"date\"], axis=1)\n",
    "X_data_test = X_data[X_data[\"date\"].isin(valid_dates)].drop([\"date\"], axis=1)\n",
    "\n",
    "print(Y_data_train.shape, X_data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400bdf9-282d-475b-8518-9f3d15b3664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CROSS-VALIDATE\n",
    "\n",
    "ccaCV = rcca.CCACrossValidate(kernelcca=False, \n",
    "                              numCV = 10,\n",
    "                              numCCs = [x for x in range(1, 4)],\n",
    "                              regs = [1e6, 1e8, 1e10, 1e14, 1e18]) #[0., 1e2, 1e4, 1e6], np.array(np.logspace(-1, 4, 10)\n",
    "\n",
    "# Use the train() and validate() methods to run the analysis and perform cross-dataset prediction.\n",
    "ccaCV.train([X_data_train.values, Y_data_train.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f692c-e0ce-4713-aa41-31fdde6e7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcorrsCV = ccaCV.validate([X_data_test.values, Y_data_test.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093213a-1c4e-4558-ac79-95b2e41be6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal number of components: %d\\nOptimal regularization coefficient: %d' % (ccaCV.best_numCC, ccaCV.best_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7251470-b114-4fd4-b3b5-8dd47397a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CORRELATION BETWEEN COMPONENTS\n",
    "ccaCV.cancorrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d80b2-c7c1-40a5-8c67-e5be6379750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAINED VARIANCE\n",
    "ev = ccaCV.compute_ev([X_data_test.values, Y_data_test.values])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fe1ee-76e5-4c78-ae87-c38db5786249",
   "metadata": {},
   "source": [
    "### TESTING CORRELATION ON PREDICTED VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e0ee8-d864-4063-bda4-deb39ebf7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_test = pd.DataFrame(testcorrsCV[0], index=X_data_train.columns, columns=[\"corr\"])\n",
    "df_corr_test[\"stock\"] = df_corr_test.index.map(lambda x: x.split(\"_\")[0])\n",
    "df_corr_test = df_corr_test.groupby(\"stock\").mean().sort_values(by=\"corr\", ascending=False)\n",
    "# df_corr_test.to_csv(to_csv_path+\"{}_{}_test_corr.csv\".format(traded_asset, indicator))\n",
    "\n",
    "print(df_corr_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8d78a-195c-4d76-9333-a8d27f897cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_COMPONENTS = ccaCV.best_numCC\n",
    "\n",
    "all_ev = pd.DataFrame()\n",
    "all_wts = pd.DataFrame()\n",
    "for i in range(TOTAL_COMPONENTS): #TOTAL_COMPONENTS\n",
    "    \n",
    "    col_ev = \"ev_\"+str(i)\n",
    "    col_wts = \"wts_\"+str(i)\n",
    "    \n",
    "    df_ev = pd.DataFrame(ev[0][i], index=X_data_test.columns, columns=[col_ev]).sort_values(by=col_ev)\n",
    "    df_ev[\"stock\"] = df_ev.index.map(lambda x: x.split(\"_\")[0])\n",
    "    st_ev_df = df_ev.groupby(\"stock\").sum().sort_index()\n",
    "    all_ev = pd.concat([all_ev, st_ev_df], axis=1)\n",
    "    \n",
    "    df_loading = pd.DataFrame(ccaCV.ws[0].T[i], index=X_data_test.columns, columns=[col_wts])\n",
    "    df_loading = df_loading.abs()\n",
    "    df_loading[\"stock\"] = df_loading.index.map(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    st_wts_df = df_loading.groupby(\"stock\").sum()/df_loading.groupby(\"stock\").sum().sum()\n",
    "    st_wts_df = st_wts_df.sort_index()\n",
    "    all_wts = pd.concat([all_wts, st_wts_df], axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e42030d-a576-406e-b2c4-4c5550dc6080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loading = pd.DataFrame(ccaCV.ws[0].T[i], index=X_data_test.columns, columns=[col_wts])\n",
    "df_loading = df_loading.abs()\n",
    "df_loading[\"stock\"] = df_loading.index.map(lambda x: x.split(\"_\")[2])\n",
    "df_loading.groupby(\"stock\").sum()/df_loading.groupby(\"stock\").sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4d838-5008-4197-9396-ffd9e57cbc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a13fd8-c742-41d5-9d08-7802992b05c5",
   "metadata": {},
   "source": [
    "## CCA ON ALL THE ASSETS AND INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8d545-f11a-45be-8b54-fa670e17fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traded_asset_ls =  [\"AXISBANK\", \"BANKBARODA\", \"CANARABANK\", \"FEDERALBANK\", \"HDFCBANK\", \"ICICIBANK\", \n",
    "                 \"INDUSINDBANK\", \"KOTAKBANK\",  \"PNB\", \"SBI\"]\n",
    "\n",
    "indicator_ls = ['RSI', 'MACD.MACD', 'BBANDSSTDDIST', 'PEAKMINUSTROUGH', 'STOCH']\n",
    "remove_cols = [\"PHARMAFF33INDEX\"] #\"COALINDIA\", \"NMDC\"\n",
    "suffix = \"\" # \"wo_pharmaff\"\n",
    "\n",
    "###\n",
    "for traded_asset in traded_asset_ls:\n",
    "    print(\"\\n\", traded_asset)\n",
    "    for indicator in indicator_ls:\n",
    "        print(indicator)\n",
    "\n",
    "        Y_cols = [x for x in total_data.columns if (traded_asset in x) and (indicator in x)] + [\"date\"]\n",
    "        X_cols = [x for x in total_data.columns if (traded_asset not in x) and (indicator in x) and (x.split(\"_\")[0] not in remove_cols)] + [\"date\"]\n",
    "\n",
    "        Y_data = total_data[Y_cols]\n",
    "        X_data = total_data[X_cols]\n",
    "\n",
    "        Y_data_train = Y_data[Y_data[\"date\"].isin(train_dates)].drop([\"date\"], axis=1)\n",
    "        Y_data_test = Y_data[Y_data[\"date\"].isin(valid_dates)].drop([\"date\"], axis=1)\n",
    "\n",
    "        X_data_train = X_data[X_data[\"date\"].isin(train_dates)].drop([\"date\"], axis=1)\n",
    "        X_data_test = X_data[X_data[\"date\"].isin(valid_dates)].drop([\"date\"], axis=1)\n",
    "\n",
    "\n",
    "        ### CV\n",
    "        ccaCV = rcca.CCACrossValidate(kernelcca=False, \n",
    "                                  numCV = 10,\n",
    "                                  numCCs = [x for x in range(1, 4)],\n",
    "                                  regs = [1e6, 1e8, 1e10, 1e14, 1e18]) #[0., 1e2, 1e4, 1e6], np.array(np.logspace(-1, 4, 10)\n",
    "\n",
    "        ccaCV.train([X_data_train.values, Y_data_train.values])\n",
    "\n",
    "        testcorrsCV = ccaCV.validate([X_data_test.values, Y_data_test.values])\n",
    "        ev = ccaCV.compute_ev([X_data_test.values, Y_data_test.values])\n",
    "\n",
    "        ##\n",
    "        df_corr_test = pd.DataFrame(testcorrsCV[0], index=X_data_train.columns, columns=[\"corr\"])\n",
    "        df_corr_test[\"stock\"] = df_corr_test.index.map(lambda x: x.split(\"_\")[0])\n",
    "        df_corr_test = df_corr_test.groupby(\"stock\").mean().sort_values(by=\"corr\", ascending=False)\n",
    "        df_corr_test.to_csv(to_csv_path+\"{}_{}_test_corr_{}.csv\".format(traded_asset, indicator, suffix))\n",
    "\n",
    "\n",
    "        TOTAL_COMPONENTS = ccaCV.best_numCC\n",
    "\n",
    "        all_ev = pd.DataFrame()\n",
    "        all_wts = pd.DataFrame()\n",
    "        for i in range(TOTAL_COMPONENTS):\n",
    "\n",
    "            col_ev = \"ev_\"+str(i)\n",
    "            col_wts = \"wts_\"+str(i)\n",
    "\n",
    "            df_ev = pd.DataFrame(ev[0][i], index=X_data_test.columns, columns=[col_ev]).sort_values(by=col_ev)\n",
    "            df_ev[\"stock\"] = df_ev.index.map(lambda x: x.split(\"_\")[0])\n",
    "            st_ev_df = df_ev.groupby(\"stock\").sum().sort_index()\n",
    "            all_ev = pd.concat([all_ev, st_ev_df], axis=1)\n",
    "\n",
    "\n",
    "            df_loading = pd.DataFrame(ccaCV.ws[0].T[i], index=X_data_test.columns, columns=[col_wts])\n",
    "            df_loading = df_loading.abs()\n",
    "            df_loading[\"stock\"] = df_loading.index.map(lambda x: x.split(\"_\")[0])\n",
    "            \n",
    "            st_wts_df = df_loading.groupby(\"stock\").sum()/df_loading.groupby(\"stock\").sum().sum()\n",
    "            st_wts_df = st_wts_df.sort_index()\n",
    "            all_wts = pd.concat([all_wts, st_wts_df], axis=1)\n",
    "        \n",
    "        all_wts = all_wts.mean(axis=1).to_frame().rename(columns={0:indicator})\n",
    "        all_wts.to_csv(to_csv_path+\"{}_{}_wts_{}.csv\".format(traded_asset, indicator, suffix))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ea192-2a74-438e-8c2b-247091822dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237cbc2-5829-4463-bafb-12d61c26c9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
